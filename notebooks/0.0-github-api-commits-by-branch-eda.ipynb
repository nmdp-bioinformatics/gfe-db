{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub API EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8s/9sb2nsn913q7b4zz75fd_qf00000gn/T/ipykernel_1653/1475131825.py:8: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv('/Users/ammon/Projects/nmdp-bioinformatics/02-Repositories/gfe-db/.env.nmdpf');\n",
    "from itertools import chain, starmap\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variables\n",
    "AWS_REGION = os.environ[\"AWS_REGION\"] \n",
    "GITHUB_PERSONAL_ACCESS_TOKEN = os.environ[\"GITHUB_PERSONAL_ACCESS_TOKEN\"]\n",
    "GITHUB_REPOSITORY_OWNER = \"ANHIG\" # os.environ[\"GITHUB_REPOSITORY_OWNER\"]\n",
    "GITHUB_REPOSITORY_NAME = \"IMGTHLA\" # os.environ[\"GITHUB_REPOSITORY_NAME\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = Path('.').resolve().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_json(dictionary, sep='.', skip_fields=[]):\n",
    "    \"\"\"Flatten a nested json file. For a list of dictionaries, use this\n",
    "    inside a for loop before converting to pandas DataFrame.\"\"\"\n",
    "\n",
    "    def unpack(parent_key, parent_value):\n",
    "        \"\"\"Unpack one level of nesting in json file\"\"\"\n",
    "        # Unpack one level only!!!\n",
    "        \n",
    "        if isinstance(parent_value, dict):\n",
    "            for key, value in parent_value.items():\n",
    "                temp1 = parent_key + sep + key\n",
    "                yield temp1, value\n",
    "        elif isinstance(parent_value, list):\n",
    "            i = 0 \n",
    "            for value in parent_value:\n",
    "                temp2 = parent_key + sep +str(i) \n",
    "                i += 1\n",
    "                yield temp2, value\n",
    "        else:\n",
    "            yield parent_key, parent_value    \n",
    "\n",
    "\n",
    "    # Keep iterating until the termination condition is satisfied\n",
    "    while True:\n",
    "        # Keep unpacking the json file until all values are atomic elements (not dictionary or list)\n",
    "        dictionary = dict(chain.from_iterable(starmap(unpack, dictionary.items())))\n",
    "        # Terminate condition: not any value in the json file is dictionary or list\n",
    "        if not any(isinstance(value, dict) for value in dictionary.values()) and \\\n",
    "           not any(isinstance(value, list) for value in dictionary.values()):\n",
    "            break\n",
    "\n",
    "    return dictionary\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commits(owner, repo, per_page=100):\n",
    "    \"\"\"Return a list of GitHub commits for the specified repository\"\"\"\n",
    "\n",
    "    base_url = 'https://api.github.com'\n",
    "\n",
    "    # Endpoint\n",
    "    endpoint = f'/repos/{owner}/{repo}/commits?per_page={per_page}'\n",
    "\n",
    "    url = base_url + endpoint\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_PERSONAL_ACCESS_TOKEN}',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'X-GitHub-Api-Version': '2022-11-28'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_commit(owner, repo, commit_sha):\n",
    "    \"\"\"Return the commit for the specified repository and commit SHA\"\"\"\n",
    "\n",
    "    base_url = 'https://api.github.com'\n",
    "\n",
    "    # Endpoint\n",
    "    endpoint = f'/repos/{owner}/{repo}/commits/{commit_sha}'\n",
    "    url = base_url + endpoint\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_PERSONAL_ACCESS_TOKEN}',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'X-GitHub-Api-Version': '2022-11-28'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branches(owner, repo):\n",
    "    \"\"\"Fetch branches for a GitHub repository\"\"\"\n",
    "\n",
    "    base_url = 'https://api.github.com'\n",
    "\n",
    "    # Endpoint\n",
    "    endpoint = f'/repos/{owner}/{repo}/branches'\n",
    "    url = base_url + endpoint\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_PERSONAL_ACCESS_TOKEN}',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'X-GitHub-Api-Version': '2022-11-28'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    branches = response.json()\n",
    "\n",
    "    return branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_branch(owner, repo, branch_name):\n",
    "    \"\"\"Fetch branches for a GitHub repository\"\"\"\n",
    "\n",
    "    base_url = 'https://api.github.com'\n",
    "\n",
    "    # Endpoint\n",
    "    endpoint = f'/repos/{owner}/{repo}/branches/{branch_name}'\n",
    "    url = base_url + endpoint\n",
    "\n",
    "    # Headers\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_PERSONAL_ACCESS_TOKEN}',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'X-GitHub-Api-Version': '2022-11-28'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "    branches = response.json()\n",
    "\n",
    "    return branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to fetch pull requests\n",
    "def fetch_pull_requests(owner, repo):\n",
    "    url = f\"https://api.github.com/repos/{owner}/{repo}/pulls?state=all\"\n",
    "    \n",
    "    # Headers\n",
    "    headers = {\n",
    "        'Authorization': f'token {GITHUB_PERSONAL_ACCESS_TOKEN}',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/vnd.github.v3+json',\n",
    "        'X-GitHub-Api-Version': '2022-11-28'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commits by Branch\n",
    "This data was previously downloaded as a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygethub import list_branches, list_commits, GitHubPaginator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginator = GitHubPaginator(GITHUB_PERSONAL_ACCESS_TOKEN)\n",
    "\n",
    "# # BRANCHES\n",
    "# branch_pages = paginator.get_paginator(list_branches, owner=GITHUB_REPOSITORY_OWNER, repo=GITHUB_REPOSITORY_NAME)\n",
    "# all_branches = list(branch_pages)\n",
    "\n",
    "# # TODO 2/10/24\n",
    "# # TODO extract the branch names\n",
    "# branch_names = [branch[\"name\"] for branch in all_branches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commits_by_branch = {}\n",
    "# for branch in branch_names:\n",
    "#     list_commits_params = {\n",
    "#         \"owner\": GITHUB_REPOSITORY_OWNER,\n",
    "#         \"repo\": GITHUB_REPOSITORY_NAME,\n",
    "#         \"sha\": branch,\n",
    "#     }\n",
    "#     branch_commit_pages = paginator.get_paginator(\n",
    "#         list_commits, \n",
    "#         **list_commits_params,\n",
    "#         user_agent=\"nmdp-bioinformatics-gfe-db-state-builder/1.0\")\n",
    "#     commits_by_branch[branch] = list(branch_commit_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(root_dir / \"commits-by-branch.json\", \"w\") as f:\n",
    "#     json.dump(commits_by_branch, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load commits-by-branch.json\n",
    "with open(root_dir / \"commits-by-branch.json\", \"r\") as f:\n",
    "    commits_by_branch = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits by Branch EDA\n",
    "\n",
    "Reshape commits_by_branch JSON using dict and list comprehensions\n",
    "Example of input structure\n",
    "```json\n",
    "{\n",
    "    \"300\": [\n",
    "        {\n",
    "            \"sha\": \"ba5cb3d05c7b3ba5024cdafa192d89af186f08a9\",\n",
    "            \"node_id\": \"MDY6Q29tbWl0MjQ1NDAxMzY6YmE1Y2IzZDA1YzdiM2JhNTAyNGNkYWZhMTkyZDg5YWYxODZmMDhhOQ==\",\n",
    "            \"commit\": {\n",
    "                \"author\": {\n",
    "                    \"name\": \"anhig\",\n",
    "                    \"email\": \"james.robinson@anthonynolan.org\",\n",
    "                    \"date\": \"2017-06-07T13:49:28Z\"\n",
    "                },\n",
    "                \"committer\": {\n",
    "                    \"name\": \"anhig\",\n",
    "                    \"email\": \"james.robinson@anthonynolan.org\",\n",
    "                    \"date\": \"2017-06-07T13:49:28Z\"\n",
    "                },\n",
    "                \"message\": \"Addition of historical WMDA files\\n\\nAddition of historical WMDA files\",\n",
    "                \"tree\": {\n",
    "                    \"sha\": \"9eafc92b0944c5e08f7c4b9faeb75c491d293a8a\",\n",
    "                    \"url\": \"https://api.github.com/repos/ANHIG/IMGTHLA/git/trees/9eafc92b0944c5e08f7c4b9faeb75c491d293a8a\"\n",
    "                },\n",
    "                \"url\": \"https://api.github.com/repos/ANHIG/IMGTHLA/git/commits/ba5cb3d05c7b3ba5024cdafa192d89af186f08a9\",\n",
    "                \"comment_count\": 0,\n",
    "                \"verification\": {\n",
    "                    \"verified\": false,\n",
    "                    \"reason\": \"unsigned\",\n",
    "                    \"signature\": null,\n",
    "                    \"payload\": null\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        ...\n",
    "    ],\n",
    "    ...\n",
    "}\n",
    "```\n",
    "Example of output structure\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"branch\": \"300\",\n",
    "        \"sha\": \"ba5cb3d05c7b3ba5024cdafa192d89af186f08a9\",\n",
    "        \"node_id\": \"MDY6Q29tbWl0MjQ1NDAxMzY6YmE1Y2IzZDA1YzdiM2JhNTAyNGNkYWZhMTkyZDg5YWYxODZmMDhhOQ==\",\n",
    "        \"commit\": {\n",
    "            \"author\": {\n",
    "                \"name\": \"anhig\",\n",
    "                \"email\": \"james.robinson@anthonynolan.org\",\n",
    "                \"date\": \"2017-06-07T13:49:28Z\"\n",
    "            },\n",
    "            \"committer\": {\n",
    "                \"name\": \"anhig\",\n",
    "                \"email\": \"james.robinson@anthonynolan.org\",\n",
    "                \"date\": \"2017-06-07T13:49:28Z\"\n",
    "            },\n",
    "            \"message\": \"Addition of historical WMDA files\\n\\nAddition of historical WMDA files\",\n",
    "            \"tree\": {\n",
    "                \"sha\": \"9eafc92b0944c5e08f7c4b9faeb75c491d293a8a\",\n",
    "                \"url\": \"https://api.github.com/repos/ANHIG/IMGTHLA/git/trees/9eafc92b0944c5e08f7c4b9faeb75c491d293a8a\"\n",
    "            },\n",
    "            \"url\": \"https://api.github.com/repos/ANHIG/IMGTHLA/git/commits/ba5cb3d05c7b3ba5024cdafa192d89af186f08a9\",\n",
    "            \"comment_count\": 0,\n",
    "            \"verification\": {\n",
    "                \"verified\": false,\n",
    "                \"reason\": \"unsigned\",\n",
    "                \"signature\": null,\n",
    "                \"payload\": null\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits_by_branch_list = [\n",
    "    {\n",
    "        \"branch\": branch,\n",
    "        **commit\n",
    "    }\n",
    "    for branch, commits in commits_by_branch.items()\n",
    "    for commit in commits\n",
    "]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten the commits_by_branch_list\n",
    "commits_by_branch_list_flat = [flatten_json(commit) for commit in commits_by_branch_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load to pandas DataFrame\n",
    "commits_by_branch_df = pd.DataFrame(commits_by_branch_list_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregation below shows that a single sha can be associated with multiple branches. This means that we cannot rely on the branch name to indicate the release version the commit was made for.\n",
    "\n",
    "Also notice that some commits are associated with only one branch. These are the commits that were missing from calling list_commits which defaults to the master branch, which in this case is called 'Latest'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by sha and find unique branches, then include a column for the number of branches and sort from least to most\n",
    "commits_by_sha = commits_by_branch_df.groupby(\"sha\").agg(\n",
    "    branches=(\"branch\", \"unique\"),\n",
    "    date=(\"commit.author.date\", \"first\"),\n",
    "    num_branches=(\"branch\", \"nunique\"),\n",
    "    # html_url=(\"html_url\", \"first\"),\n",
    ").sort_values(\"date\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commits_by_sha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sha</th>\n",
       "      <th>branches</th>\n",
       "      <th>date</th>\n",
       "      <th>num_branches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>e1cd1ec3e66f4ab2b218f6758ed315f557778655</td>\n",
       "      <td>[3130]</td>\n",
       "      <td>2017-06-21T14:40:46Z</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sha branches                  date  \\\n",
       "270  e1cd1ec3e66f4ab2b218f6758ed315f557778655   [3130]  2017-06-21T14:40:46Z   \n",
       "\n",
       "     num_branches  \n",
       "270             1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commits_by_sha[commits_by_sha[\"sha\"] == \"e1cd1ec3e66f4ab2b218f6758ed315f557778655\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commits_by_sha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commits by Branch Processing\n",
    "Reduce commits-by-branch JSON to a list of unique commits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of all unique commits in commits_by_branch and omit the branch information\n",
    "unique_commits = set()\n",
    "for release, commits in commits_by_branch.items():\n",
    "    unique_commits.update([json.dumps(commit) for commit in commits])\n",
    "\n",
    "# covert back to dict\n",
    "unique_commits = [json.loads(commit) for commit in unique_commits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_commits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_commits_flat = [flatten_json(commit) for commit in unique_commits]\n",
    "unique_commits_df = pd.DataFrame(unique_commits_flat).sort_values(\"commit.author.date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort by date\n",
    "len(unique_commits_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_commits_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_commits_df[['sha', 'commit.author.date', 'commit.message', 'html_url']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Error SHAs\n",
    "Some SHAs do not allow files to be retrieved using the GitHub REST API:\n",
    "```json\n",
    "[\n",
    "    \"8d77b3dd93959663d58ae5b626289d0746edd0e7\",\n",
    "    \"252d7c5dc9d2f7671447fd11fe6bb004c438f34b\",\n",
    "    \"e1cd1ec3e66f4ab2b218f6758ed315f557778655\",\n",
    "    \"fa208da83a7f96d62c1e4efee2018074bbd805e0\",\n",
    "    \"09ed08b9abcd97622d59ec37e31b4706dc9a9391\",\n",
    "    \"8db938b1eb58dd8c77cba9b7524f84cf8ffe719c\",\n",
    "    \"041318439bf0ba291f990faaa27cd6ad0a062d13\",\n",
    "    \"ba5cb3d05c7b3ba5024cdafa192d89af186f08a9\",\n",
    "    \"7ca4eb239a96884142d3ef0b0182d3bc84ec1bba\",\n",
    "    \"3abe7e12dcbc3824315959af4428c53bd760c6e7\",\n",
    "    \"c4d3f67ef7ef4b5f6571b4f1d4aa5b928d2a3d56\",\n",
    "    \"23044ee80c27f75bb34c9f9ac689b1c68cd65914\"\n",
    "]\n",
    "```\n",
    "\n",
    "In this case version 300 is still missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Recent Commit by Branch\n",
    "Evaluating API responses with the objective of finding the most recent data for a given release.\n",
    "- All releases are available as branches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1: 57 items\n"
     ]
    }
   ],
   "source": [
    "paginator = GitHubPaginator(GITHUB_PERSONAL_ACCESS_TOKEN)\n",
    "\n",
    "### COMMITS BY BRANCHES ###\n",
    "branch_pages = paginator.get_paginator(\n",
    "    list_branches, \n",
    "    owner=GITHUB_REPOSITORY_OWNER, \n",
    "    repo=GITHUB_REPOSITORY_NAME,\n",
    "    user_agent=\"nmdp-bioinformatics-gfe-db-state-builder/1.0\"\n",
    ")\n",
    "all_branches = list(branch_pages)\n",
    "\n",
    "# # extract the branch names\n",
    "# branch_names = [branch[\"name\"] for branch in all_branches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3550',\n",
       " 'commit': {'sha': 'e4fd1e39a4d9f1da8e7efe4a7f699320e287dcdb',\n",
       "  'url': 'https://api.github.com/repos/ANHIG/IMGTHLA/commits/e4fd1e39a4d9f1da8e7efe4a7f699320e287dcdb'},\n",
       " 'protected': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_branches[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': '3520',\n",
       "  'commit': {'sha': '62945381d236dcdb2770daf1fa861b216b99635c',\n",
       "   'url': 'https://api.github.com/repos/ANHIG/IMGTHLA/commits/62945381d236dcdb2770daf1fa861b216b99635c'},\n",
       "  'protected': False},\n",
       " {'name': '3530',\n",
       "  'commit': {'sha': '83aa94b540407ccdfcb452c77439b86c543f849d',\n",
       "   'url': 'https://api.github.com/repos/ANHIG/IMGTHLA/commits/83aa94b540407ccdfcb452c77439b86c543f849d'},\n",
       "  'protected': False},\n",
       " {'name': '3540',\n",
       "  'commit': {'sha': '7d00d7b49cbcc987e07752845bd8b14986316ab4',\n",
       "   'url': 'https://api.github.com/repos/ANHIG/IMGTHLA/commits/7d00d7b49cbcc987e07752845bd8b14986316ab4'},\n",
       "  'protected': False},\n",
       " {'name': '3550',\n",
       "  'commit': {'sha': 'e4fd1e39a4d9f1da8e7efe4a7f699320e287dcdb',\n",
       "   'url': 'https://api.github.com/repos/ANHIG/IMGTHLA/commits/e4fd1e39a4d9f1da8e7efe4a7f699320e287dcdb'},\n",
       "  'protected': False},\n",
       " {'name': 'Latest',\n",
       "  'commit': {'sha': 'df6ba6f80a2c5f999590f06fced6c4c4ff56b89d',\n",
       "   'url': 'https://api.github.com/repos/ANHIG/IMGTHLA/commits/df6ba6f80a2c5f999590f06fced6c4c4ff56b89d'},\n",
       "  'protected': False}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_branches[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write json to file for all-branches\n",
    "with open(root_dir / \"all-branches.json\", \"w\") as f:\n",
    "    json.dump(all_branches, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
